import torch
from torch import nn
from layer import (
    CheckinEmbedding,
    EdgeEmbedding,
    HypergraphTransformer,
    TimeEncoder,
    DistanceEncoderHSTLSTM,
    DistanceEncoderSTAN,
    DistanceEncoderSimple
)
from torch_sparse import SparseTensor
import torch.nn.functional as F
import logging

class STHGCN(nn.Module):
    """
    æ”¹é€ ç‰ˆ STHGCNï¼šå…¼å®¹ä¸¤ç§è¾“å…¥æ¨¡å¼?
      - å…¨å›¾ / ä¸‰å±‚è¶…å›¾å­—å…¸è¾“å…¥ï¼ˆåŸå…ˆçš„æ¨¡å¼ï¼?: data æ˜? dictï¼ŒåŒ…å? 'x', 'edge_index', 'edge_attr', 'delta_ts', 'delta_ss', 'edge_type', 'candidates', 'labels' ç­?
      - é‚»å±…é‡‡æ · / mini-batchï¼ˆPyG-likeï¼?: data æ˜? Batch-like objectï¼Œå¯èƒ½åŒ…å? adjs_t / edge_index / edge_attrs / edge_delta_ts / edge_delta_ss / edge_types / x / y ç­?

    ä¸»è¦æ”¹åŠ¨ç‚¹å·²æ ‡æ³¨ä¸? # [MODIFIED] /  
    """
    def __init__(self, cfg, dataset):
        super(STHGCN, self).__init__()
        # æ³¨æ„ï¼šcfg.run_args.device å¯èƒ½æ˜¯å­—ç¬¦ä¸² 'cuda:0' æˆ? 'cpu'
        self.device = cfg.run_args.device
        self.batch_size = cfg.run_args.batch_size
        self.eval_batch_size = cfg.run_args.eval_batch_size
        self.do_traj2traj = cfg.model_args.do_traj2traj
        self.distance_encoder_type = cfg.model_args.distance_encoder_type
        self.dropout_rate = cfg.model_args.dropout_rate
        self.generate_edge_attr = cfg.model_args.generate_edge_attr
        self.num_conv_layers = len(cfg.model_args.sizes)
        self.num_poi = cfg.dataset_args.num_poi
        self.embed_fusion_type = cfg.model_args.embed_fusion_type
        self.fusion_type = getattr(cfg.model_args, "embed_fusion_type",
                    getattr(cfg.model_args, "fusion_type", "concat"))

        # === è·å–ç‰¹å¾ç»´åº¦ï¼ˆä¿æŒä½ ä¹‹å‰çš„ç¡¬ç¼–ç /æˆ–å¯æ”¹ä¸ºä»? dataset è‡ªåŠ¨æ‹¿ï¼‰ ===
        entity_feat_dim = 9
        event_feat_dim = 7
        chain_feat_dim = 8

        logging.info(f"Feature dimensions - Entity: {entity_feat_dim}, Event: {event_feat_dim}, Chain: {chain_feat_dim}")

        # === ä¸‰å±‚è¶…å›¾ Embedding ===
        self.checkin_embedding_layer = CheckinEmbedding(
            embed_size=cfg.model_args.embed_size,
            fusion_type=self.fusion_type,
            entity_feat_dim=entity_feat_dim,
            event_feat_dim=event_feat_dim,
            chain_feat_dim=chain_feat_dim
        )
        self.checkin_embed_size = self.checkin_embedding_layer.output_embed_size

        # === è¾¹ç±»å‹åµŒå…? ===
        self.edge_type_embedding_layer = EdgeEmbedding(
            embed_size=self.checkin_embed_size,
            fusion_type=self.embed_fusion_type,
            num_edge_type=cfg.model_args.num_edge_type
        )

        # === æ¿€æ´»å‡½æ•? ===
        if cfg.model_args.activation == 'elu':
            self.act = nn.ELU()
        elif cfg.model_args.activation == 'relu':
            self.act = nn.RReLU()
        elif cfg.model_args.activation == 'leaky_relu':
            self.act = nn.LeakyReLU()
        else:
            self.act = torch.tanh

        # === æ—¶é—´ç¼–ç å™¨ç»´åº? ===
        if cfg.conv_args.time_fusion_mode == 'add':
            continuous_encoder_dim = self.checkin_embed_size
        else:
            continuous_encoder_dim = cfg.model_args.st_embed_size
        if continuous_encoder_dim <= 0:
            continuous_encoder_dim = 64
            logging.warning(f"Invalid continuous_encoder_dim, using default: {continuous_encoder_dim}")
        logging.info(f"Time encoder dimension: {continuous_encoder_dim}")

        # === æ—¶é—´ + è·ç¦» ç¼–ç å™? (ä½¿ç”¨ä½ ä¹‹å‰é‚£ç‰ˆå¯åˆ†å—/CPUè®¡ç®—ä¼˜åŒ–çš? TimeEncoder) ===
        # [MODIFIED] ç¡®ä¿ TimeEncoder æ”¯æŒ chunk_size, compute_on_cpu ç­‰ï¼ˆä½ çš„æ”¹ç‰ˆä¸­å·²æœ‰ï¼‰
        self.continuous_time_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim,
                                                  chunk_size=32768, compute_on_cpu=True, out_dtype=torch.float32)
        if self.distance_encoder_type == 'stan':
            self.continuous_distance_encoder = DistanceEncoderSTAN(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
        elif self.distance_encoder_type == 'time':
            # ç”¨æ—¶é—´ç¼–ç å™¨ä½œä¸ºè·ç¦»ç¼–ç å™¨ï¼ˆå¯å¤ç”¨ï¼‰
            self.continuous_distance_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim,
                                                          chunk_size=32768, compute_on_cpu=True, out_dtype=torch.float32)
        elif self.distance_encoder_type == 'hstlstm':
            self.continuous_distance_encoder = DistanceEncoderHSTLSTM(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
        elif self.distance_encoder_type == 'simple':
            self.continuous_distance_encoder = DistanceEncoderSimple(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
        else:
            raise ValueError(f"Wrong distance_encoder_type: {self.distance_encoder_type}!")

        # === è¾¹å±æ€§åµŒå…¥å±‚ ===
        if self.generate_edge_attr:
            self.edge_attr_embedding_layer = EdgeEmbedding(
                embed_size=self.checkin_embed_size,
                fusion_type=self.embed_fusion_type,
                num_edge_type=cfg.model_args.num_edge_type
            )
        else:
            if cfg.conv_args.edge_fusion_mode == 'add':
                self.edge_attr_embedding_layer = nn.Linear(3, self.checkin_embed_size)
            else:
                self.edge_attr_embedding_layer = None

        # === ç¬¬ä¸€å±? Entityâ†’Event è¶…å›¾å·ç§¯ ===
        self.conv_for_time_filter = HypergraphTransformer(
            in_channels=self.checkin_embed_size,
            out_channels=self.checkin_embed_size,
            attn_heads=cfg.conv_args.num_attention_heads,
            residual_beta=cfg.conv_args.residual_beta,
            learn_beta=cfg.conv_args.learn_beta,
            dropout=cfg.conv_args.conv_dropout_rate,
            trans_method=cfg.conv_args.trans_method,
            edge_fusion_mode=cfg.conv_args.edge_fusion_mode,
            time_fusion_mode=cfg.conv_args.time_fusion_mode,
            head_fusion_mode=cfg.conv_args.head_fusion_mode,
            residual_fusion_mode=None,
            edge_dim=None,
            rel_embed_dim=self.checkin_embed_size,
            time_embed_dim=continuous_encoder_dim,
            dist_embed_dim=continuous_encoder_dim,
            negative_slope=cfg.conv_args.negative_slope,
            have_query_feature=False
        )
        self.norms_for_time_filter = nn.BatchNorm1d(self.checkin_embed_size)
        self.dropout_for_time_filter = nn.Dropout(self.dropout_rate)

        # === Eventâ†’Chain å·ç§¯ï¼ˆå¤šå±‚ï¼‰ ===
        self.conv_list = nn.ModuleList()
        if self.do_traj2traj:
            for i in range(self.num_conv_layers):
                have_query_feature = (i > 0)
                residual_fusion_mode = None if i == 0 else cfg.conv_args.residual_fusion_mode
                edge_size = None if self.edge_attr_embedding_layer is None else self.checkin_embed_size

                self.conv_list.append(
                    HypergraphTransformer(
                        in_channels=self.checkin_embed_size,
                        out_channels=self.checkin_embed_size,
                        attn_heads=cfg.conv_args.num_attention_heads,
                        residual_beta=cfg.conv_args.residual_beta,
                        learn_beta=cfg.conv_args.learn_beta,
                        dropout=cfg.conv_args.conv_dropout_rate,
                        trans_method=cfg.conv_args.trans_method,
                        edge_fusion_mode=cfg.conv_args.edge_fusion_mode,
                        time_fusion_mode=cfg.conv_args.time_fusion_mode,
                        head_fusion_mode=cfg.conv_args.head_fusion_mode,
                        residual_fusion_mode=residual_fusion_mode,
                        edge_dim=edge_size,
                        rel_embed_dim=self.checkin_embed_size,
                        time_embed_dim=continuous_encoder_dim,
                        dist_embed_dim=continuous_encoder_dim,
                        negative_slope=cfg.conv_args.negative_slope,
                        have_query_feature=have_query_feature
                    )
                )
            self.norms_list = nn.ModuleList([nn.BatchNorm1d(self.checkin_embed_size) for _ in range(self.num_conv_layers)])
            self.dropout_list = nn.ModuleList([nn.Dropout(self.dropout_rate) for _ in range(self.num_conv_layers)])

        # === è¾“å‡ºå±‚ï¼šå°¾äº‹ä»¶åˆ†ç±? ===
        self.linear = nn.Linear(self.checkin_embed_size, dataset.num_event)
        self.loss_func = nn.CrossEntropyLoss()


    # -------------------------
      è¾…åŠ©ï¼šæŠŠ Batch-like å¯¹è±¡è½¬ä¸º model éœ€è¦çš„ dict æ ¼å¼ï¼ˆå®¹é”™ï¼‰
    # -------------------------
    def _batch_to_input_dict(self, batch):
        """
        æ¥å—ä¸€ä¸? Batch-like å¯¹è±¡ï¼ˆæ¥è‡? NeighborSampler æˆ–è‡ªå®šä¹‰ samplerï¼‰ï¼Œ
        å°†å¯èƒ½çš„å­—æ®µåæ ‡å‡†åŒ–æˆ? model æ‰€éœ€çš? dictã€?
        å…¼å®¹å­—æ®µï¼ˆæ ¹æ®ä½ çš? pipeline å¯èƒ½å­˜åœ¨çš„åå­—ï¼‰ï¼?
          - node features: batch.x æˆ? (batch.entity_x, batch.event_x, batch.chain_x)
          - edge_index / adjs_t: batch.edge_index / batch.adjs_t
          - edge attributes: batch.edge_attr / batch.edge_attrs
          - delta times: batch.delta_ts / batch.edge_delta_ts
          - delta spaces: batch.delta_ss / batch.edge_delta_ss
          - edge types: batch.edge_type / batch.edge_types
          - candidates: batch.candidates
          - labels: batch.labels or batch.y
        """
        input_data = {}

        # node features
        if hasattr(batch, 'x'):
            input_data['x'] = batch.x
        elif hasattr(batch, 'entity_x') and hasattr(batch, 'event_x') and hasattr(batch, 'chain_x'):
            input_data['x'] = (batch.entity_x, batch.event_x, batch.chain_x)
        else:
            # è‹¥æ²¡æœ‰æ‰¾åˆ°ï¼Œè®¾ä¸º Noneï¼ˆä¸Šå±‚ä¼šæŠ¥é”™ï¼?
            input_data['x'] = getattr(batch, 'x', None)

        # edge_index can be either adjs_t (list of SparseTensor) or edge_index
        if hasattr(batch, 'adjs_t'):
            input_data['edge_index'] = batch.adjs_t
        else:
            input_data['edge_index'] = getattr(batch, 'edge_index', None)

        # edge attributes
        input_data['edge_attr'] = getattr(batch, 'edge_attr', getattr(batch, 'edge_attrs', None))

        # delta times & delta spaces
        input_data['delta_ts'] = getattr(batch, 'delta_ts', getattr(batch, 'edge_delta_ts', None))
        input_data['delta_ss'] = getattr(batch, 'delta_ss', getattr(batch, 'edge_delta_ss', None))

        # edge type
        input_data['edge_type'] = getattr(batch, 'edge_type', getattr(batch, 'edge_types', None))

        # candidates and labels
        input_data['candidates'] = getattr(batch, 'candidates', None)
        # labels might be batch.labels or batch.y
        labels = getattr(batch, 'labels', None)
        if labels is None:
            labels = getattr(batch, 'y', None)
        input_data['labels'] = labels

        # split_index: neighbor-sampler å¸¸ä¼šç”? adjs_tï¼Œå°è¯•è®¡ç®? split_indexï¼ˆå®¹é”™ï¼‰
        split_index = getattr(batch, 'split_index', None)
        if split_index is None and hasattr(batch, 'adjs_t'):
            try:
                # PyG çš? SparseTensor å­˜å‚¨æ¥å£å¯èƒ½ä¸åŒï¼Œä¹‹å‰? pipeline ä½¿ç”¨ï¼?
                # torch.max(row.adjs_t[1].storage.row()).tolist() æ¥è®¡ç®? split_index
                split_index = int(torch.max(batch.adjs_t[1].storage.row()).item())
            except Exception:
                split_index = None
        input_data['split_index'] = split_index

        return input_data


    # -------------------------
    # forwardï¼šå…¼å®? dictï¼ˆå…¨å›¾ï¼‰å’? Batch-likeï¼ˆé‡‡æ ·ï¼‰
    # -------------------------
    def forward(self, data, label=None, mode='train'):
        """
        data å¯ä»¥æ˜¯ï¼š
          - dictï¼šå…¨å›¾ï¼ˆä¸‰å±‚è¶…å›¾ï¼‰æ¨¡å¼ï¼ˆä¸åŸç‰ˆå…¼å®¹ï¼‰
          - Batch-likeï¼ˆæœ‰ adjs_t / edge_index / edge_delta_ts ç­‰ï¼‰ï¼šé‡‡æ ·æ¨¡å¼?
        """
        # å¦‚æœ data ä¸æ˜¯ dictï¼Œå°†å…¶è½¬æ¢ä¸ºæ ‡å‡† dict
        if isinstance(data, dict):
            input_data = data
        else:
            # [MODIFIED] ä½¿ç”¨è¾…åŠ©å‡½æ•°è¿›è¡Œå®¹é”™è½¬æ¢
            input_data = self._batch_to_input_dict(data)

        # ç¡®ä¿ node features å­˜åœ¨å¹¶ä¸”æ˜¯ä¸‰å…ƒç»„ (entity,event,chain) çš„å½¢å¼?
        if isinstance(input_data.get('x', None), (list, tuple)) and len(input_data['x']) == 3:
            entity_x, event_x, chain_x = input_data['x']
        else:
            # å¦‚æœä¸æ˜¯ä¸‰å…ƒç»„ï¼Œå°è¯•ä»? batch çš„å±æ€§æ‹†åˆ†ï¼ˆæç«¯æƒ…å†µï¼?
            # è¿™é‡Œä¿åº•åœ°æŠŠ input_data['x'] è§†ä½œ entity_xï¼›event_x/chain_x ç½? Noneï¼ˆè‹¥åç»­éœ€è¦æ”¹ï¼?
            ent = input_data.get('x')
            entity_x = ent
            event_x = None
            chain_x = None

        # æŠŠè¾“å…¥å¼ é‡ç§»åŠ¨åˆ° model.deviceï¼ˆå¦‚æœæä¾›äº†è®¾å¤‡ä¿¡æ¯ï¼?
        target_device = torch.device(self.device) if isinstance(self.device, str) else self.device

        # å¦‚æœ entity/event/chain çš„å¼ é‡å­˜åœ¨ï¼ŒæŠŠå®ƒä»¬ç§»åŠ¨åˆ° device
        if isinstance(entity_x, torch.Tensor):
            entity_x = entity_x.to(target_device)
        if isinstance(event_x, torch.Tensor):
            event_x = event_x.to(target_device)
        if isinstance(chain_x, torch.Tensor):
            chain_x = chain_x.to(target_device)

        # === 1. èŠ‚ç‚¹åµŒå…¥ï¼ˆæ— è®ºå…¨å›¾è¿˜æ˜¯é‡‡æ ·ï¼ŒCheckinEmbedding æ¥å£ç›¸åŒï¼? ===
        # [MODIFIED] å…¼å®¹ç¼ºå¤± event_x/chain_x çš„æƒ…å†?
        x = self.checkin_embedding_layer(entity_x, event_x, chain_x)

        # === 2. è¾¹çš„æ—¶é—´/ç©ºé—´ç‰¹å¾ï¼ˆEntityâ†’Eventï¼? ===
        # delta_ts å¯èƒ½æ˜? list/tupleï¼ˆæ¯å±‚ä¸€ä»½ï¼‰ï¼Œä¹Ÿå¯èƒ½æ˜¯å•ä¸? tensorï¼ˆç¬¬ä¸€å±‚ï¼‰
        delta_ts_input = input_data.get('delta_ts', None)
        if isinstance(delta_ts_input, (list, tuple)):
            delta_ts_first = delta_ts_input[0]
        else:
            delta_ts_first = delta_ts_input

        edge_time_embed = None
        if delta_ts_first is not None:
            # å°? delta_ts è½¬åˆ° device å¹¶è½¬æ¢ä¸º float32ï¼ŒæŒ‰å°æ—¶å½’ä¸€ï¼ˆä½ çš„åŸå®ç°ï¼?
            delta_ts_first = delta_ts_first.to(target_device).to(torch.float32)
            edge_time_embed = self.continuous_time_encoder(delta_ts_first / (60 * 60))
            logging.info(f"Delta_ts shape: {delta_ts_first.shape}")
            # åªæ‰“å°å‰ 5 ä¸ªæ ·æœ¬ï¼ˆå¦‚æœå¯ç”¨ï¼?
            try:
                logging.info(f"Delta_ts sample values: {delta_ts_first[:5]}")
            except Exception:
                pass
        else:
            logging.info("Warning: delta_ts for first layer is None.")

        # delta_ssï¼ˆè·ç¦»ï¼‰
        delta_ss_input = input_data.get('delta_ss', None)
        if isinstance(delta_ss_input, (list, tuple)):
            delta_ss_first = delta_ss_input[0]
        else:
            delta_ss_first = delta_ss_input

        edge_distance_embed = None
        if delta_ss_first is not None:
            delta_ss_first = delta_ss_first.to(target_device).to(torch.float32)
            if self.distance_encoder_type == 'stan':
                # å¦‚æœæ˜? stanï¼Œä¼ å…? dist_type æ ‡è¯†
                edge_distance_embed = self.continuous_distance_encoder(delta_ss_first, dist_type='entity2event')
            else:
                edge_distance_embed = self.continuous_distance_encoder(delta_ss_first)
        else:
            logging.info("Warning: delta_ss for first layer is None.")

        # === 3. Entityâ†’Event å·ç§¯ ===
        edge_attr_embed, edge_type_embed = None, None
        first_edge_type = None
        edge_type_input = input_data.get('edge_type', None)
        if isinstance(edge_type_input, (list, tuple)):
            first_edge_type = edge_type_input[0]
        else:
            first_edge_type = edge_type_input

        if first_edge_type is not None:
            # æ³¨æ„ï¼šEdgeEmbedding æœŸå¾… LongTensor indicesï¼›ç¡®ä¿ç±»å‹æ­£ç¡?
            if isinstance(first_edge_type, torch.Tensor):
                first_edge_type = first_edge_type.to(target_device).long()
            if self.generate_edge_attr:
                edge_attr_embed = self.edge_attr_embedding_layer(first_edge_type)
            edge_type_embed = self.edge_type_embedding_layer(first_edge_type)

        # edge_index é¦–å±‚
        edge_index_input = input_data.get('edge_index', None)
        edge_index_first = None
        if isinstance(edge_index_input, (list, tuple)):
            edge_index_first = edge_index_input[0]
        else:
            edge_index_first = edge_index_input

        x_for_time_filter = self.conv_for_time_filter(
            x,
            edge_index=edge_index_first,
            edge_attr_embed=edge_attr_embed,
            edge_time_embed=edge_time_embed,
            edge_dist_embed=edge_distance_embed,
            edge_type_embed=edge_type_embed
        )
        x_for_time_filter = self.norms_for_time_filter(x_for_time_filter)
        x_for_time_filter = self.act(x_for_time_filter)
        x_for_time_filter = self.dropout_for_time_filter(x_for_time_filter)

        # === 4. Eventâ†’Chain å·ç§¯ï¼ˆå¤šå±‚ï¼‰ ===
        # é€å±‚éå† edge_index/edge_attr/delta_ts/delta_ss/edge_typeï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if input_data.get('edge_index', None) is not None and self.do_traj2traj:
            # iterate layers 1..end
            # extract lists or tuples or singletons
            edge_index_list = input_data.get('edge_index')
            edge_attr_list = input_data.get('edge_attr')
            delta_ts_list = input_data.get('delta_ts')
            delta_ss_list = input_data.get('delta_ss')
            edge_type_list = input_data.get('edge_type')

            # defensive: ensure these are iterables
            def _as_list(x):
                if x is None:
                    return []
                if isinstance(x, (list, tuple)):
                    return list(x)
                # if it's a single tensor (only first layer), return list with that element repeated? we return single item
                return [x]

            edge_index_list = _as_list(edge_index_list)
            edge_attr_list = _as_list(edge_attr_list)
            delta_ts_list = _as_list(delta_ts_list)
            delta_ss_list = _as_list(delta_ss_list)
            edge_type_list = _as_list(edge_type_list)

            # iterate (skip first because we already used layer 0)
            for idx in range(1, len(edge_index_list)):
                edge_index = edge_index_list[idx]
                edge_attr = edge_attr_list[idx] if idx < len(edge_attr_list) else None
                delta_ts = delta_ts_list[idx] if idx < len(delta_ts_list) else None
                delta_dis = delta_ss_list[idx] if idx < len(delta_ss_list) else None
                edge_type = edge_type_list[idx] if idx < len(edge_type_list) else None

                # compute time & distance embedding for this layer
                edge_time_embed = None
                if delta_ts is not None:
                    edge_time_embed = self.continuous_time_encoder(delta_ts.to(target_device).to(torch.float32) / (60 * 60))
                if delta_dis is not None:
                    if self.distance_encoder_type == 'stan':
                        edge_distance_embed = self.continuous_distance_encoder(delta_dis.to(target_device).to(torch.float32), dist_type='event2chain')
                    else:
                        edge_distance_embed = self.continuous_distance_encoder(delta_dis.to(target_device).to(torch.float32))

                # edge type and attr for this layer
                edge_attr_embed, edge_type_embed = None, None
                if edge_type is not None:
                    edge_type = edge_type.to(target_device).long()
                    edge_type_embed = self.edge_type_embedding_layer(edge_type)
                    if self.generate_edge_attr:
                        edge_attr_embed = self.edge_attr_embedding_layer(edge_type)
                    elif self.edge_attr_embedding_layer and edge_attr is not None:
                        edge_attr_embed = self.edge_attr_embedding_layer(edge_attr.to(target_device).to(torch.float32))
                    elif edge_attr is not None:
                        edge_attr_embed = edge_attr.to(target_device).to(torch.float32)

                # === ç¡®å®š x_target (query / target nodes for this convolution) ===
                if idx == len(edge_index_list) - 1:
                    # last conv layer: target is batch (å€™é€‰æ‰¹æ¬?)
                    batch_size = self.eval_batch_size if mode in ('test', 'validate') else self.batch_size
                    x_target = x_for_time_filter[:batch_size]
                else:
                    # éæœ€åä¸€å±‚ï¼štarget æ˜¯å‰é¢èŠ‚ç‚¹æ•°ï¼ˆæ ¹æ? edge_index çš? max idx æ¨æ–­ï¼?
                    try:
                        # edge_index might be SparseTensor or dense index; if it has max() method:
                        if isinstance(edge_index, torch.Tensor):
                            num_nodes = int(edge_index.max().item()) + 1
                        elif isinstance(edge_index, SparseTensor):
                            num_nodes = int(edge_index.sizes()[0])
                        else:
                            # fallback
                            num_nodes = x_for_time_filter.size(0)
                        x_target = x_for_time_filter[:num_nodes]
                    except Exception:
                        x_target = x_for_time_filter

                # perform convolution for this layer
                x = self.conv_list[idx - 1](
                    (x_for_time_filter, x_target),
                    edge_index=edge_index,
                    edge_attr_embed=edge_attr_embed,
                    edge_time_embed=edge_time_embed,
                    edge_dist_embed=edge_distance_embed,
                    edge_type_embed=edge_type_embed
                )
                x = self.norms_list[idx - 1](x)
                x = self.act(x)
                x = self.dropout_list[idx - 1](x)
        else:
            # no traj2traj convs
            x = x_for_time_filter

        # === 5. åˆ†ç±»é¢„æµ‹ï¼ˆå°¾äº‹ä»¶ï¼? ===
        logits = self.linear(x)  # shape: [num_nodes_in_x, num_event]

        # === 6. åªå–å€™é€‰äº‹ä»¶çš„ logitsï¼ˆå¦‚æ? candidates å­˜åœ¨ï¼? ===
        candidates = input_data.get('candidates', None)   # [B, K] or None
        labels = input_data.get('labels', None)           # [B] or [B,1]

        if candidates is None:
            # æ²¡æœ‰å€™é€‰é›†åˆï¼Œåˆ™ç›´æ¥è¿”å›? logitsï¼ˆå¯èƒ½ç”¨äºå…¶å®ƒç”¨é€”ï¼‰
            loss = None
            if labels is not None:
                # è‹? labels å­˜åœ¨ä¸? logits è¡Œæ•°ç­‰äº labels é•¿åº¦ï¼ˆç›´æ¥ç›‘ç£ï¼‰
                try:
                    loss = self.loss_func(logits, labels.long())
                except Exception:
                    logging.info("Labels present but shape mismatch with logits; returning None loss.")
                    loss = None
            return logits, loss

        # candidates éœ€è¦æ˜¯ LongTensor, å¹¶ä¸”ä½äº device ä¸?
        candidates = candidates.long().to(target_device)
        B, K = candidates.size()
        logging.info(f"logits shape: {logits.shape}")
        logging.info(f"candidates shape: {candidates.shape}")
        try:
            logging.info(f"candidates range: {int(candidates.min().item())} {int(candidates.max().item())}")
        except Exception:
            pass

        # logits: [N_nodes, num_event]ï¼Œæˆ‘ä»¬å‡è®? N_nodes å¯¹åº”äº? batch çš„ç¬¬ä¸€ä¸ªç»´åº? Bï¼ˆä¾‹å¦‚æœ€åä¸€å±? x[:B])
        # å¦‚æœ logits çš„ç¬¬ä¸€ç»´ä¸ B ä¸åŒï¼Œéœ€è¦ä¿è¯æˆ‘ä»¬å–åˆ°çš„æ˜¯é’ˆå¯? batch çš? logitsï¼ˆä¸Šå±‚å·²ä¿è¯ï¼?
        # ç”? gather åœ¨åˆ—ç»´åº¦ä¸Šå–å€™é€‰äº‹ä»¶å¯¹åº”çš„åˆ†æ•°
        # ä¸ºæ­¤éœ€è¦? logits å¤§å°ä¸? [B, num_event]ï¼ˆæˆ– [N, num_event]ï¼Œä½† candidates ç´¢å¼•å¯¹åº”äºåŒä¸€ N)
        # æˆ‘ä»¬åšå°½é‡ç¨³å¥çš„ gatherï¼?
        if logits.size(0) == B:
            candidate_logits = logits.gather(1, candidates)   # [B, K]
        else:
            # å¦‚æœ logits è¡Œæ•° != Bï¼Œå°è¯•å°† logits é¦? B è¡Œä½œä¸? batch å¯¹åº”
            if logits.size(0) >= B:
                candidate_logits = logits[:B].gather(1, candidates)
            else:
                # æ­¤å¤„è¯´æ˜ä¸Šå±‚ x_target / batch_size æ¨æ–­å¯èƒ½æœ‰é—®é¢?
                # ä¸ºäº†é¿å…æŠ›é”™ï¼Œå°è¯? expand logits åˆ? Bï¼ˆä¼šé‡å¤æ•°æ®ï¼Œç»“æœä¸æ­£ç¡®ä½†ä¸ä¼? crashï¼?
                logging.warning("logits row count doesn't match batch size; attempting fallback (may be incorrect).")
                tiled = logits.repeat(int((B + logits.size(0) - 1) // logits.size(0)), 1)[:B]
                candidate_logits = tiled.gather(1, candidates)

        loss = None
        if labels is not None:
            # gold logits: [B, 1]
            gold = labels.view(-1, 1).long().to(target_device)
            # å¦‚æœ gold ä¸­çš„ç´¢å¼•è¶…å‡º boundsï¼Œä¼šæŠ›é”™ï¼›è¿™é‡Œå‡è®? labels æ˜¯äº‹ä»? idï¼ˆcol idxï¼?
            gold_logits = logits.gather(1, gold) if logits.size(0) >= gold.size(0) else logits[:B].gather(1, gold)
            # æ‹¼æ¥ [B, 1+K]
            logits_for_loss = torch.cat([gold_logits, candidate_logits], dim=1)
            target = torch.zeros(B, dtype=torch.long, device=logits.device)
            loss = F.cross_entropy(logits_for_loss, target)

        return candidate_logits, loss

# import torch
# from torch import nn
# from layer import (
#     CheckinEmbedding,
#     EdgeEmbedding,
#     HypergraphTransformer,
#     TimeEncoder,
#     DistanceEncoderHSTLSTM,
#     DistanceEncoderSTAN,
#     DistanceEncoderSimple
# )
# from torch_sparse import SparseTensor
# import torch.nn.functional as F
# # å¯¼å…¥æ—¥å¿—è®°å½•åº?
# import logging
# class STHGCN(nn.Module):
#     def __init__(self, cfg, dataset):   # [MODIFIED] å¢åŠ  dataset å‚æ•°
#         super(STHGCN, self).__init__()
#         self.device = cfg.run_args.device
#         self.batch_size = cfg.run_args.batch_size
#         self.eval_batch_size = cfg.run_args.eval_batch_size
#         self.do_traj2traj = cfg.model_args.do_traj2traj
#         self.distance_encoder_type = cfg.model_args.distance_encoder_type
#         self.dropout_rate = cfg.model_args.dropout_rate
#         self.generate_edge_attr = cfg.model_args.generate_edge_attr
#         self.num_conv_layers = len(cfg.model_args.sizes)
#         self.num_poi = cfg.dataset_args.num_poi
#         self.embed_fusion_type = cfg.model_args.embed_fusion_type
#         self.fusion_type = getattr(cfg.model_args, "embed_fusion_type",
#                     getattr(cfg.model_args, "fusion_type", "concat"))

#         # # === è·å–ç‰¹å¾ç»´åº¦ ===
#         # # [MODIFIED] ä»? dataset è·å–ç‰¹å¾ç»´åº¦
#         # entity_feat_dim = dataset.entity_x.shape[1] if hasattr(dataset, 'entity_x') else 0
#         # event_feat_dim = dataset.event_x.shape[1] if hasattr(dataset, 'event_x') else 0
#         # chain_feat_dim = dataset.chain_x.shape[1] if hasattr(dataset, 'chain_x') else 0
        
#         # logging.info(f"Feature dimensions - Entity: {entity_feat_dim}, Event: {event_feat_dim}, Chain: {chain_feat_dim}")

#         # # === ä¸‰å±‚è¶…å›¾ Embedding ===
#         # # [MODIFIED] ä½¿ç”¨ç‰¹å¾ç»´åº¦è€Œä¸æ˜¯èŠ‚ç‚¹æ•°é‡?
#         # self.checkin_embedding_layer = CheckinEmbedding(
#         #     embed_size=cfg.model_args.embed_size,
#         #     fusion_type=self.fusion_type,
#         #     entity_feat_dim=entity_feat_dim,
#         #     event_feat_dim=event_feat_dim,
#         #     chain_feat_dim=chain_feat_dim
#         # )
#         # # åœ? STHGCN çš? __init__ æ–¹æ³•ä¸­ä¿®æ”¹ç‰¹å¾ç»´åº¦è·å–éƒ¨åˆ?

#         # === è·å–ç‰¹å¾ç»´åº¦ ===
#         # [MODIFIED] ç›´æ¥ä»æ•°æ®é›†ä¸­è·å–ç‰¹å¾ç»´åº?
#         # ä»è°ƒè¯•ä¿¡æ¯ä¸­å¯ä»¥çœ‹åˆ°å®é™…çš„ç‰¹å¾ç»´åº?
#         entity_feat_dim = 9  # ä»è°ƒè¯•ä¿¡æ¯ä¸­å¯ä»¥çœ‹åˆ° entity_x.shape[1] = 9
#         event_feat_dim = 7   # ä»è°ƒè¯•ä¿¡æ¯ä¸­å¯ä»¥çœ‹åˆ° event_x.shape[1] = 7  
#         chain_feat_dim = 8   # ä»è°ƒè¯•ä¿¡æ¯ä¸­å¯ä»¥çœ‹åˆ° chain_x.shape[1] = 8

#         logging.info(f"Feature dimensions - Entity: {entity_feat_dim}, Event: {event_feat_dim}, Chain: {chain_feat_dim}")

#         # === ä¸‰å±‚è¶…å›¾ Embedding ===
#         self.checkin_embedding_layer = CheckinEmbedding(
#             embed_size=cfg.model_args.embed_size,
#             fusion_type=self.fusion_type,
#             entity_feat_dim=entity_feat_dim,  # ä½¿ç”¨ç¡¬ç¼–ç çš„ç‰¹å¾ç»´åº¦
#             event_feat_dim=event_feat_dim,
#             chain_feat_dim=chain_feat_dim
#         )

#         self.checkin_embed_size = self.checkin_embedding_layer.output_embed_size

#         # === è¾¹ç±»å‹åµŒå…? ===
#         self.edge_type_embedding_layer = EdgeEmbedding(
#             embed_size=self.checkin_embed_size,
#             fusion_type=self.embed_fusion_type,
#             num_edge_type=cfg.model_args.num_edge_type
#         )

#         # === æ¿€æ´»å‡½æ•? ===
#         if cfg.model_args.activation == 'elu':
#             self.act = nn.ELU()
#         elif cfg.model_args.activation == 'relu':
#             self.act = nn.RReLU()
#         elif cfg.model_args.activation == 'leaky_relu':
#             self.act = nn.LeakyReLU()
#         else:
#             self.act = torch.tanh

#         # # === æ—¶é—´ç¼–ç å™¨ç»´åº? ===
#         # if cfg.conv_args.time_fusion_mode == 'add':
#         #     continuous_encoder_dim = self.checkin_embed_size
#         # else:
#         #     continuous_encoder_dim = cfg.model_args.st_embed_size

        
#         # === æ—¶é—´ç¼–ç å™¨ç»´åº? ===
#         # [MODIFIED] ç¡®ä¿æ—¶é—´ç¼–ç å™¨ç»´åº¦æ­£ç¡?
#         if cfg.conv_args.time_fusion_mode == 'add':
#             continuous_encoder_dim = self.checkin_embed_size
#         else:
#             continuous_encoder_dim = cfg.model_args.st_embed_size

#         # æ£€æŸ¥ç»´åº¦æœ‰æ•ˆæ€?
#         if continuous_encoder_dim <= 0:
#             continuous_encoder_dim = 64  # è®¾ç½®åˆç†çš„é»˜è®¤å€?
#             logging.warning(f"Invalid continuous_encoder_dim, using default: {continuous_encoder_dim}")

#         logging.info(f"Time encoder dimension: {continuous_encoder_dim}")

#         # === æ—¶é—´ + è·ç¦» ç¼–ç å™? ===
#         #self.continuous_time_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim)
#         self.continuous_time_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim,
#                                           chunk_size=32768, compute_on_cpu=True, out_dtype=torch.float32)
#         if self.distance_encoder_type == 'stan':
#             self.continuous_distance_encoder = DistanceEncoderSTAN(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
#         elif self.distance_encoder_type == 'time':
#             #self.continuous_distance_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim)
#             self.continuous_distance_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim,
#                                           chunk_size=32768, compute_on_cpu=True, out_dtype=torch.float32)
#         elif self.distance_encoder_type == 'hstlstm':
#             self.continuous_distance_encoder = DistanceEncoderHSTLSTM(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
#         elif self.distance_encoder_type == 'simple':
#             self.continuous_distance_encoder = DistanceEncoderSimple(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
#         else:
#             raise ValueError(f"Wrong distance_encoder_type: {self.distance_encoder_type}!")

#         # === è¾¹å±æ€§åµŒå…¥å±‚ ===
#         if self.generate_edge_attr:
#             self.edge_attr_embedding_layer = EdgeEmbedding(
#                 embed_size=self.checkin_embed_size,
#                 fusion_type=self.embed_fusion_type,
#                 num_edge_type=cfg.model_args.num_edge_type
#             )
#         else:
#             if cfg.conv_args.edge_fusion_mode == 'add':
#                 self.edge_attr_embedding_layer = nn.Linear(3, self.checkin_embed_size)
#             else:
#                 self.edge_attr_embedding_layer = None

#         # === ç¬¬ä¸€å±? Entityâ†’Event è¶…å›¾å·ç§¯ ===
#         self.conv_for_time_filter = HypergraphTransformer(
#             in_channels=self.checkin_embed_size,
#             out_channels=self.checkin_embed_size,
#             attn_heads=cfg.conv_args.num_attention_heads,
#             residual_beta=cfg.conv_args.residual_beta,
#             learn_beta=cfg.conv_args.learn_beta,
#             dropout=cfg.conv_args.conv_dropout_rate,
#             trans_method=cfg.conv_args.trans_method,
#             edge_fusion_mode=cfg.conv_args.edge_fusion_mode,
#             time_fusion_mode=cfg.conv_args.time_fusion_mode,
#             head_fusion_mode=cfg.conv_args.head_fusion_mode,
#             residual_fusion_mode=None,
#             edge_dim=None,
#             rel_embed_dim=self.checkin_embed_size,
#             time_embed_dim=continuous_encoder_dim,
#             dist_embed_dim=continuous_encoder_dim,
#             negative_slope=cfg.conv_args.negative_slope,
#             have_query_feature=False
#         )
#         self.norms_for_time_filter = nn.BatchNorm1d(self.checkin_embed_size)
#         self.dropout_for_time_filter = nn.Dropout(self.dropout_rate)

#         # === Eventâ†’Chain å·ç§¯ï¼ˆå¤šå±‚ï¼‰ ===
#         self.conv_list = nn.ModuleList()
#         if self.do_traj2traj:
#             for i in range(self.num_conv_layers):
#                 have_query_feature = (i > 0)
#                 residual_fusion_mode = None if i == 0 else cfg.conv_args.residual_fusion_mode
#                 edge_size = None if self.edge_attr_embedding_layer is None else self.checkin_embed_size

#                 self.conv_list.append(
#                     HypergraphTransformer(
#                         in_channels=self.checkin_embed_size,
#                         out_channels=self.checkin_embed_size,
#                         attn_heads=cfg.conv_args.num_attention_heads,
#                         residual_beta=cfg.conv_args.residual_beta,
#                         learn_beta=cfg.conv_args.learn_beta,
#                         dropout=cfg.conv_args.conv_dropout_rate,
#                         trans_method=cfg.conv_args.trans_method,
#                         edge_fusion_mode=cfg.conv_args.edge_fusion_mode,
#                         time_fusion_mode=cfg.conv_args.time_fusion_mode,
#                         head_fusion_mode=cfg.conv_args.head_fusion_mode,
#                         residual_fusion_mode=residual_fusion_mode,
#                         edge_dim=edge_size,
#                         rel_embed_dim=self.checkin_embed_size,
#                         time_embed_dim=continuous_encoder_dim,
#                         dist_embed_dim=continuous_encoder_dim,
#                         negative_slope=cfg.conv_args.negative_slope,
#                         have_query_feature=have_query_feature
#                     )
#                 )
#             self.norms_list = nn.ModuleList([nn.BatchNorm1d(self.checkin_embed_size) for _ in range(self.num_conv_layers)])
#             self.dropout_list = nn.ModuleList([nn.Dropout(self.dropout_rate) for _ in range(self.num_conv_layers)])

#         # === æ—¶é—´ + è·ç¦» ç¼–ç å™? ===
#         #self.continuous_time_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim)

#         # è®? chunk æ›´å°äº›ã€å¹¶åœ? CPU ä¸Šè®¡ç®—ä»¥å°½é‡èŠ‚çœ GPU
#         self.continuous_time_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim,
#                                           chunk_size=32768, compute_on_cpu=True, out_dtype=torch.float32)
#         # self.continuous_time_encoder = TimeEncoderEfficient(args, embedding_dim, chunk_size=1024, use_linear=False, use_fp16=False)
#         if self.distance_encoder_type == 'stan':
#             self.continuous_distance_encoder = DistanceEncoderSTAN(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
#         elif self.distance_encoder_type == 'time':
#             #self.continuous_distance_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim)
#             self.continuous_distance_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim,
#                                           chunk_size=32768, compute_on_cpu=True, out_dtype=torch.float32)
#         elif self.distance_encoder_type == 'hstlstm':
#             self.continuous_distance_encoder = DistanceEncoderHSTLSTM(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
#         elif self.distance_encoder_type == 'simple':
#             self.continuous_distance_encoder = DistanceEncoderSimple(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
#         else:
#             raise ValueError(f"Wrong distance_encoder_type: {self.distance_encoder_type}!")

#         # === è¾“å‡ºå±‚ï¼šå°¾äº‹ä»¶åˆ†ç±? ===
#         self.linear = nn.Linear(self.checkin_embed_size, dataset.num_event)
#         self.loss_func = nn.CrossEntropyLoss()


#     def forward(self, data, label=None, mode='train'):

#         # === [MODIFIED] å…¼å®¹ torch_geometric Batch æˆ? dict ===
#         if not isinstance(data, dict):
#             input_data = {
#                 'x': (input_data['entity_x'], input_data['event_x'], input_data['chain_x']),
#                 'edge_index': input_data['edge_index'],
#                 'edge_attr': input_data['edge_attr'],
#                 'delta_ts': input_data['delta_ts'],
#                 'delta_ss': input_data['delta_ss'],
#                 'edge_type': input_data['edge_type'],
#                 'candidates': input_data['candidates'],
#                 'labels': input_data['labels']
#             }
#         else:
#             input_data = data

#         # === 1. èŠ‚ç‚¹åµŒå…¥ ===
#         # [MODIFIED] æ‹†åˆ† entity_x, event_x, chain_x
#         entity_x = input_data['x'][0]
#         event_x = input_data['x'][1]
#         chain_x = input_data['x'][2] 
        
#         # [MODIFIED] ç§»é™¤è°ƒè¯•æ‰“å°ï¼Œå› ä¸ºç°åœ¨å¤„ç†çš„æ˜¯ç‰¹å¾çŸ©é˜µä¸æ˜¯ç´¢å¼?
#         # logging.info("entity_x min/max:", entity_x.min().item(), entity_x.max().item())
#         # logging.info("event_x min/max:", event_x.min().item(), event_x.max().item())
#         # logging.info("chain_x min/max:", chain_x.min().item(), chain_x.max().item())
        
#         x = self.checkin_embedding_layer(entity_x, event_x, chain_x)

#         # === 2. è¾¹çš„æ—¶é—´/ç©ºé—´ç‰¹å¾ï¼ˆEntityâ†’Eventï¼? ===
#         # === 2. è¾¹çš„æ—¶é—´/ç©ºé—´ç‰¹å¾ï¼ˆEntityâ†’Eventï¼? ===
#         delta_ts = input_data['delta_ts'][0] / (60 * 60)
#         logging.info(f"Delta_ts shape: {delta_ts.shape}")
#         logging.info(f"Delta_ts sample values: {delta_ts[:5]}")  # æŸ¥çœ‹å‰?5ä¸ªå€?
#         edge_time_embed = self.continuous_time_encoder(delta_ts)
#         #edge_time_embed = self.continuous_time_encoder(input_data['delta_ts'][0] / (60 * 60))
#         if self.distance_encoder_type == 'stan':
#             edge_distance_embed = self.continuous_distance_encoder(input_data['delta_ss'][0], dist_type='entity2event')
#         else:
#             edge_distance_embed = self.continuous_distance_encoder(input_data['delta_ss'][0])

#         edge_time_embed = self.continuous_time_encoder(delta_ts)
#         # === 3. Entityâ†’Event å·ç§¯ ===
#         edge_attr_embed, edge_type_embed = None, None
#         if input_data['edge_type'][0] is not None:
#             if self.generate_edge_attr:
#                 edge_attr_embed = self.edge_attr_embedding_layer(input_data['edge_type'][0])
#             edge_type_embed = self.edge_type_embedding_layer(input_data['edge_type'][0])

#         x_for_time_filter = self.conv_for_time_filter(
#             x,
#             edge_index=input_data['edge_index'][0],
#             edge_attr_embed=edge_attr_embed,
#             edge_time_embed=edge_time_embed,
#             edge_dist_embed=edge_distance_embed,
#             edge_type_embed=edge_type_embed
#         )
#         x_for_time_filter = self.norms_for_time_filter(x_for_time_filter)
#         x_for_time_filter = self.act(x_for_time_filter)
#         x_for_time_filter = self.dropout_for_time_filter(x_for_time_filter)

#         # === 4. Eventâ†’Chain å·ç§¯ ===
#         if input_data['edge_index'][-1] is not None and self.do_traj2traj:
#             for idx, (edge_index, edge_attr, delta_ts, delta_dis, edge_type) in enumerate(
#                     zip(input_data["edge_index"][1:], input_data["edge_attr"][1:], 
#                         input_data["delta_ts"][1:], input_data["delta_ss"][1:], 
#                         input_data["edge_type"][1:])
#             ):
#                 edge_time_embed = self.continuous_time_encoder(delta_ts / (60 * 60))
#                 if self.distance_encoder_type == 'stan':
#                     edge_distance_embed = self.continuous_distance_encoder(delta_dis, dist_type='event2chain')
#                 else:
#                     edge_distance_embed = self.continuous_distance_encoder(delta_dis)

#                 edge_attr_embed, edge_type_embed = None, None
#                 if edge_type is not None:
#                     edge_type_embed = self.edge_type_embedding_layer(edge_type)
#                     if self.generate_edge_attr:
#                         edge_attr_embed = self.edge_attr_embedding_layer(edge_type)
#                     elif self.edge_attr_embedding_layer:
#                         edge_attr_embed = self.edge_attr_embedding_layer(edge_attr.to(torch.float32))
#                     else:
#                         edge_attr_embed = edge_attr.to(torch.float32)

#                 # === ç¡®ä¿ x_target å®šä¹‰ ===
#                 if idx == len(input_data['edge_index']) - 2:
#                     batch_size = self.eval_batch_size if mode in ('test', 'validate') else self.batch_size
#                     x_target = x_for_time_filter[:batch_size]
#                 else:
#                     if edge_index is not None:
#                         # x_target = x[:edge_index.sparse_sizes()[0]]
#                         num_nodes = int(edge_index.max()) + 1   # æ›¿ä»£ edge_index.sparse_sizes()[0]
#                         x_target = x[:num_nodes]
#                     else:
#                         # å›é€€ï¼šå¦‚æ? edge_index æ˜? Noneï¼Œç›´æ¥ç”¨ x_for_time_filter
#                         x_target = x_for_time_filter

#                 x = self.conv_list[idx](
#                     (x_for_time_filter, x_target),
#                     edge_index=edge_index,
#                     edge_attr_embed=edge_attr_embed,
#                     edge_time_embed=edge_time_embed,
#                     edge_dist_embed=edge_distance_embed,
#                     edge_type_embed=edge_type_embed
#                 )
#                 x = self.norms_list[idx](x)
#                 x = self.act(x)
#                 x = self.dropout_list[idx](x)
#         else:
#             x = x_for_time_filter



#         # === 5. åˆ†ç±»é¢„æµ‹ï¼ˆå°¾äº‹ä»¶ï¼? ===
#         logits = self.linear(x)

#         # === [FIXED] åªå–å€™é€‰äº‹ä»¶çš„ logits ===
#         candidates = input_data['candidates']   # [B, K]
#         labels = input_data['labels']           # [B] or [B, 1]

#         B, K = candidates.size()
#         logging.info("logits shape:", logits.shape)
#         logging.info("candidates shape:", candidates.shape)
#         logging.info("candidates range:", candidates.min().item(), candidates.max().item())

#         # logits: [B, num_event]
#         # candidates: [B, K] -> åœ¨åˆ—ç»´åº¦ gather
#         candidate_logits = logits.gather(1, candidates)   # [B, K]

#         loss = None
#         if labels is not None:
#             # gold logits: [B, 1]
#             gold_logits = logits.gather(1, labels.view(-1, 1))

#             # æ‹¼æ¥ [B, 1+K]ï¼Œgold æ”¾åœ¨ç¬¬ä¸€åˆ?
#             logits_for_loss = torch.cat([gold_logits, candidate_logits], dim=1)

#             # target æ˜¯å…¨ 0ï¼Œå› ä¸? gold åœ¨ç¬¬ 0 åˆ?
#             target = torch.zeros(B, dtype=torch.long, device=logits.device)

#             loss = F.cross_entropy(logits_for_loss, target)

#         return candidate_logits, loss











#         # # === [MODIFIED] åªå–å€™é€‰äº‹ä»¶çš„ logits ===
#         # candidates = input_data['candidates']   # [B, K]
#         # labels = input_data['labels']

#         # B, K = candidates.size()
#         # logging.info("logits shape:", logits.shape)
#         # logging.info("candidates shape:", candidates.shape)
#         # logging.info("candidates range:", candidates.min().item(), candidates.max().item())

#         # candidate_logits = logits[candidates.view(-1)]  # [B*K, num_event]
#         # candidate_logits = candidate_logits.view(B, K, -1)  # [B, K, num_event]

#         # if candidate_logits.size(-1) == 1:
#         #     candidate_logits = candidate_logits.squeeze(-1)  # [B, K]

#         # loss = None
#         # if labels is not None:
#         #     loss = self.loss_func(candidate_logits, labels.long())

#         # return candidate_logits, loss
#     # import torch
# # from torch import nn
# # from layer import (
# #     CheckinEmbedding,
# #     EdgeEmbedding,
# #     HypergraphTransformer,
# #     TimeEncoder,
# #     DistanceEncoderHSTLSTM,
# #     DistanceEncoderSTAN,
# #     DistanceEncoderSimple
# # )


# # class STHGCN(nn.Module):
# #     def __init__(self, cfg, dataset):   # [MODIFIED] å¢åŠ  dataset å‚æ•°
# #         super(STHGCN, self).__init__()
# #         self.device = cfg.run_args.device
# #         self.batch_size = cfg.run_args.batch_size
# #         self.eval_batch_size = cfg.run_args.eval_batch_size
# #         self.do_traj2traj = cfg.model_args.do_traj2traj
# #         self.distance_encoder_type = cfg.model_args.distance_encoder_type
# #         self.dropout_rate = cfg.model_args.dropout_rate
# #         self.generate_edge_attr = cfg.model_args.generate_edge_attr
# #         self.num_conv_layers = len(cfg.model_args.sizes)
# #         self.num_poi = cfg.dataset_args.num_poi
# #         self.embed_fusion_type = cfg.model_args.embed_fusion_type
# #         self.fusion_type = getattr(cfg.model_args, "embed_fusion_type",
# #                     getattr(cfg.model_args, "fusion_type", "concat"))

# #         # === ä¸‰å±‚è¶…å›¾ Embedding ===
# #         self.checkin_embedding_layer = CheckinEmbedding(
# #             embed_size=cfg.model_args.embed_size,
# #             fusion_type=self.fusion_type,
# #             num_entity=dataset.num_entity,   # [MODIFIED]
# #             num_event=dataset.num_event,     # [MODIFIED]
# #             num_chain=dataset.num_eventchain      # [MODIFIED]
# #         )

# #         self.checkin_embed_size = self.checkin_embedding_layer.output_embed_size  # concat â†? 2*embed_size

# #         # === è¾¹ç±»å‹åµŒå…? ===
# #         self.edge_type_embedding_layer = EdgeEmbedding(
# #             embed_size=self.checkin_embed_size,
# #             fusion_type=self.embed_fusion_type,
# #             num_edge_type=cfg.model_args.num_edge_type
# #         )

# #         # === æ¿€æ´»å‡½æ•? ===
# #         if cfg.model_args.activation == 'elu':
# #             self.act = nn.ELU()
# #         elif cfg.model_args.activation == 'relu':
# #             self.act = nn.RReLU()
# #         elif cfg.model_args.activation == 'leaky_relu':
# #             self.act = nn.LeakyReLU()
# #         else:
# #             self.act = torch.tanh

# #         # === æ—¶é—´ç¼–ç å™¨ç»´åº? ===
# #         if cfg.conv_args.time_fusion_mode == 'add':
# #             continuous_encoder_dim = self.checkin_embed_size
# #         else:
# #             continuous_encoder_dim = cfg.model_args.st_embed_size

# #         # === è¾¹å±æ€§åµŒå…¥å±‚ ===
# #         if self.generate_edge_attr:
# #             self.edge_attr_embedding_layer = EdgeEmbedding(
# #                 embed_size=self.checkin_embed_size,
# #                 fusion_type=self.embed_fusion_type,
# #                 num_edge_type=cfg.model_args.num_edge_type
# #             )
# #         else:
# #             if cfg.conv_args.edge_fusion_mode == 'add':
# #                 self.edge_attr_embedding_layer = nn.Linear(3, self.checkin_embed_size)
# #             else:
# #                 self.edge_attr_embedding_layer = None

# #         # === ç¬¬ä¸€å±? Entityâ†’Event è¶…å›¾å·ç§¯ ===
# #         self.conv_for_time_filter = HypergraphTransformer(
# #             in_channels=self.checkin_embed_size,
# #             out_channels=self.checkin_embed_size,
# #             attn_heads=cfg.conv_args.num_attention_heads,
# #             residual_beta=cfg.conv_args.residual_beta,
# #             learn_beta=cfg.conv_args.learn_beta,
# #             dropout=cfg.conv_args.conv_dropout_rate,
# #             trans_method=cfg.conv_args.trans_method,
# #             edge_fusion_mode=cfg.conv_args.edge_fusion_mode,
# #             time_fusion_mode=cfg.conv_args.time_fusion_mode,
# #             head_fusion_mode=cfg.conv_args.head_fusion_mode,
# #             residual_fusion_mode=None,
# #             edge_dim=None,
# #             rel_embed_dim=self.checkin_embed_size,
# #             time_embed_dim=continuous_encoder_dim,
# #             dist_embed_dim=continuous_encoder_dim,
# #             negative_slope=cfg.conv_args.negative_slope,
# #             have_query_feature=False
# #         )
# #         self.norms_for_time_filter = nn.BatchNorm1d(self.checkin_embed_size)
# #         self.dropout_for_time_filter = nn.Dropout(self.dropout_rate)

# #         # === Eventâ†’Chain å·ç§¯ï¼ˆå¤šå±‚ï¼‰ ===
# #         self.conv_list = nn.ModuleList()
# #         if self.do_traj2traj:
# #             for i in range(self.num_conv_layers):
# #                 have_query_feature = (i > 0)
# #                 residual_fusion_mode = None if i == 0 else cfg.conv_args.residual_fusion_mode
# #                 edge_size = None if self.edge_attr_embedding_layer is None else self.checkin_embed_size

# #                 self.conv_list.append(
# #                     HypergraphTransformer(
# #                         in_channels=self.checkin_embed_size,
# #                         out_channels=self.checkin_embed_size,
# #                         attn_heads=cfg.conv_args.num_attention_heads,
# #                         residual_beta=cfg.conv_args.residual_beta,
# #                         learn_beta=cfg.conv_args.learn_beta,
# #                         dropout=cfg.conv_args.conv_dropout_rate,
# #                         trans_method=cfg.conv_args.trans_method,
# #                         edge_fusion_mode=cfg.conv_args.edge_fusion_mode,
# #                         time_fusion_mode=cfg.conv_args.time_fusion_mode,
# #                         head_fusion_mode=cfg.conv_args.head_fusion_mode,
# #                         residual_fusion_mode=residual_fusion_mode,
# #                         edge_dim=edge_size,
# #                         rel_embed_dim=self.checkin_embed_size,
# #                         time_embed_dim=continuous_encoder_dim,
# #                         dist_embed_dim=continuous_encoder_dim,
# #                         negative_slope=cfg.conv_args.negative_slope,
# #                         have_query_feature=have_query_feature
# #                     )
# #                 )
# #             self.norms_list = nn.ModuleList([nn.BatchNorm1d(self.checkin_embed_size) for _ in range(self.num_conv_layers)])
# #             self.dropout_list = nn.ModuleList([nn.Dropout(self.dropout_rate) for _ in range(self.num_conv_layers)])

# #         # === æ—¶é—´ + è·ç¦» ç¼–ç å™? ===
# #         self.continuous_time_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim)
# #         if self.distance_encoder_type == 'stan':
# #             self.continuous_distance_encoder = DistanceEncoderSTAN(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
# #         elif self.distance_encoder_type == 'time':
# #             self.continuous_distance_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim)
# #         elif self.distance_encoder_type == 'hstlstm':
# #             self.continuous_distance_encoder = DistanceEncoderHSTLSTM(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
# #         elif self.distance_encoder_type == 'simple':
# #             self.continuous_distance_encoder = DistanceEncoderSimple(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
# #         else:
# #             raise ValueError(f"Wrong distance_encoder_type: {self.distance_encoder_type}!")

# #         # === è¾“å‡ºå±‚ï¼šå°¾äº‹ä»¶åˆ†ç±? ===
# #         self.linear = nn.Linear(self.checkin_embed_size, dataset.num_event)  # [MODIFIED] ç”? dataset.num_event
# #         self.loss_func = nn.CrossEntropyLoss()

# #     def forward(self, data, label=None, mode='train'):

# #         # === [MODIFIED] å…¼å®¹ torch_geometric Batch æˆ? dict ===
# #         if not isinstance(data, dict):
# #             input_data = {
# #                 'x': (input_data['entity_x'], input_data['event_x'], input_data['chain_x']),
# #                 'edge_index': input_data['edge_index'],
# #                 'edge_attr': input_data['edge_attr'],
# #                 'delta_ts': input_data['delta_ts'],
# #                 'delta_ss': input_data['delta_ss'],
# #                 'edge_type': input_data['edge_type'],
# #                 'candidates': input_data['candidates'],
# #                 'labels': input_data['labels']
# #             }
# #         else:
# #             input_data = data

# #         # === 1. èŠ‚ç‚¹åµŒå…¥ ===
# #         # [MODIFIED] æ‹†åˆ† entity_x, event_x, chain_x
# #         entity_x= input_data['x'][0]
# #         event_x = input_data['x'][1]
# #         chain_x = input_data['x'][2] 
# #         x = self.checkin_embedding_layer(entity_x, event_x, chain_x)

# #         # æ‰“å°ç´¢å¼•èŒƒå›´ï¼Œæ’æŸ¥è¶Šç•?
# #         logging.info("entity_x min/max:", entity_x.min().item(), entity_x.max().item())
# #         logging.info("event_x min/max:", event_x.min().item(), event_x.max().item())
# #         logging.info("chain_x min/max:", chain_x.min().item(), chain_x.max().item())

# #         logging.info("num_entities, num_events, num_chains:", 
# #             self.entity_embedding.num_embeddings,
# #             self.event_embedding.num_embeddings,
# #             self.chain_embedding.num_embeddings)
       

# #         # === 2. è¾¹çš„æ—¶é—´/ç©ºé—´ç‰¹å¾ï¼ˆEntityâ†’Eventï¼? ===
# #         edge_time_embed = self.continuous_time_encoder(input_data['delta_ts'][0] / (60 * 60))
# #         if self.distance_encoder_type == 'stan':
# #             edge_distance_embed = self.continuous_distance_encoder(input_data['delta_ss'][0], dist_type='entity2event')
# #         else:
# #             edge_distance_embed = self.continuous_distance_encoder(input_data['delta_ss'][0])

# #         # === 3. Entityâ†’Event å·ç§¯ ===
# #         edge_attr_embed, edge_type_embed = None, None
# #         if input_data['edge_type'][0] is not None:
# #             if self.generate_edge_attr:
# #                 edge_attr_embed = self.edge_attr_embedding_layer(input_data['edge_type'][0])
# #             edge_type_embed = self.edge_type_embedding_layer(input_data['edge_type'][0])

# #         x_for_time_filter = self.conv_for_time_filter(
# #             x,
# #             edge_index=input_data['edge_index'][0],
# #             edge_attr_embed=edge_attr_embed,
# #             edge_time_embed=edge_time_embed,
# #             edge_dist_embed=edge_distance_embed,
# #             edge_type_embed=edge_type_embed
# #         )
# #         x_for_time_filter = self.norms_for_time_filter(x_for_time_filter)
# #         x_for_time_filter = self.act(x_for_time_filter)
# #         x_for_time_filter = self.dropout_for_time_filter(x_for_time_filter)

# #         # === 4. Eventâ†’Chain å·ç§¯ ===
# #         if input_data['edge_index'][-1] is not None and self.do_traj2traj:
# #             for idx, (edge_index, edge_attr, delta_ts, delta_dis, edge_type) in enumerate(
# #                     zip(input_data["edge_index"][1:], input_data["edge_attr"][1:], 
# #                         input_data["delta_ts"][1:], input_data["delta_ss"][1:], 
# #                         input_data["edge_type"][1:])
# #             ):
# #                 edge_time_embed = self.continuous_time_encoder(delta_ts / (60 * 60))
# #                 if self.distance_encoder_type == 'stan':
# #                     edge_distance_embed = self.continuous_distance_encoder(delta_dis, dist_type='event2chain')
# #                 else:
# #                     edge_distance_embed = self.continuous_distance_encoder(delta_dis)

# #                 edge_attr_embed, edge_type_embed = None, None
# #                 if edge_type is not None:
# #                     edge_type_embed = self.edge_type_embedding_layer(edge_type)
# #                     if self.generate_edge_attr:
# #                         edge_attr_embed = self.edge_attr_embedding_layer(edge_type)
# #                     elif self.edge_attr_embedding_layer:
# #                         edge_attr_embed = self.edge_attr_embedding_layer(edge_attr.to(torch.float32))
# #                     else:
# #                         edge_attr_embed = edge_attr.to(torch.float32)

# #                 if idx == len(input_data['edge_index']) - 2:
# #                     batch_size = self.eval_batch_size if mode in ('test', 'validate') else self.batch_size
# #                     x_target = x_for_time_filter[:batch_size]
# #                 else:
# #                     x_target = x[:edge_index.sparse_sizes()[0]]

# #                 x = self.conv_list[idx](
# #                     (x_for_time_filter, x_target),
# #                     edge_index=edge_index,
# #                     edge_attr_embed=edge_attr_embed,
# #                     edge_time_embed=edge_time_embed,
# #                     edge_dist_embed=edge_distance_embed,
# #                     edge_type_embed=edge_type_embed
# #                 )
# #                 x = self.norms_list[idx](x)
# #                 x = self.act(x)
# #                 x = self.dropout_list[idx](x)
# #         else:
# #             x = x_for_time_filter

# #         # === 5. åˆ†ç±»é¢„æµ‹ï¼ˆå°¾äº‹ä»¶ï¼? ===
# #         logits = self.linear(x)

# #         # === [MODIFIED] åªå–å€™é€‰äº‹ä»¶çš„ logits ===
# #         candidates = input_data['candidates']   # [B, K]
# #         labels = input_data['labels']

# #         B, K = candidates.size()
# #         candidate_logits = logits[candidates.view(-1)]  # [B*K, num_event]
# #         candidate_logits = candidate_logits.view(B, K, -1)  # [B, K, num_event]

# #         if candidate_logits.size(-1) == 1:
# #             candidate_logits = candidate_logits.squeeze(-1)  # [B, K]

# #         loss = None
# #         if labels is not None:
# #             loss = self.loss_func(candidate_logits, labels.long())

# #         return candidate_logits, loss


# #     # def forward(self, data, label=None, mode='train'):

# #     # # def forward(self, data, label=None, mode='train'):
# #     #     # [MODIFIED] å…¼å®¹ torch_geometric Batch
# #     #     # if not isinstance(data, dict):
# #     #     #     input_data = {
# #     #     #         'x': data.x,
# #     #     #         'edge_index': data.edge_index,
# #     #     #         'edge_attr': data.edge_attr,
# #     #     #         'delta_ts': data.delta_ts,
# #     #     #         'delta_ss': data.delta_ss,
# #     #     #         'edge_type': data.edge_type,
# #     #     #         'candidates': data.candidates,
# #     #     #         'labels': data.labels
# #     #     #     }
# #     #     # else:
# #     #     #     input_data = data

# #     #     entity_x, event_x, chain_x = data['x']  # ä¸‰å±‚èŠ‚ç‚¹ç‰¹å¾

# #     #     # === 1. èŠ‚ç‚¹åµŒå…¥ ===
# #     #     # [MODIFIED] ä¸€æ¬¡æ€§è¾“å…¥ï¼Œä¸è¦é‡å¤ä¸‰æ¬¡è°ƒç”¨
# #     #     x = self.checkin_embedding_layer(entity_x, event_x, chain_x)

# #     #     # === 2. è¾¹çš„æ—¶é—´/ç©ºé—´ç‰¹å¾ï¼ˆEntityâ†’Eventï¼? ===
# #     #     edge_time_embed = self.continuous_time_encoder(data['delta_ts'][0] / (60 * 60))
# #     #     if self.distance_encoder_type == 'stan':
# #     #         edge_distance_embed = self.continuous_distance_encoder(data['delta_ss'][0], dist_type='entity2event')
# #     #     else:
# #     #         edge_distance_embed = self.continuous_distance_encoder(data['delta_ss'][0])

# #     #     # === 3. Entityâ†’Event å·ç§¯ ===
# #     #     edge_attr_embed, edge_type_embed = None, None
# #     #     if data['edge_type'][0] is not None:
# #     #         if self.generate_edge_attr:
# #     #             edge_attr_embed = self.edge_attr_embedding_layer(data['edge_type'][0])
# #     #         edge_type_embed = self.edge_type_embedding_layer(data['edge_type'][0])

# #     #     x_for_time_filter = self.conv_for_time_filter(
# #     #         x,
# #     #         edge_index=data['edge_index'][0],
# #     #         edge_attr_embed=edge_attr_embed,
# #     #         edge_time_embed=edge_time_embed,
# #     #         edge_dist_embed=edge_distance_embed,
# #     #         edge_type_embed=edge_type_embed
# #     #     )
# #     #     x_for_time_filter = self.norms_for_time_filter(x_for_time_filter)
# #     #     x_for_time_filter = self.act(x_for_time_filter)
# #     #     x_for_time_filter = self.dropout_for_time_filter(x_for_time_filter)

# #     #     # === 4. Eventâ†’Chain å·ç§¯ ===
# #     #     if data['edge_index'][-1] is not None and self.do_traj2traj:
# #     #         for idx, (edge_index, edge_attr, delta_ts, delta_dis, edge_type) in enumerate(
# #     #                 zip(data["edge_index"][1:], data["edge_attr"][1:], data["delta_ts"][1:], data["delta_ss"][1:], data["edge_type"][1:])
# #     #         ):
# #     #             edge_time_embed = self.continuous_time_encoder(delta_ts / (60 * 60))
# #     #             if self.distance_encoder_type == 'stan':
# #     #                 edge_distance_embed = self.continuous_distance_encoder(delta_dis, dist_type='event2chain')
# #     #             else:
# #     #                 edge_distance_embed = self.continuous_distance_encoder(delta_dis)

# #     #             edge_attr_embed, edge_type_embed = None, None
# #     #             if edge_type is not None:
# #     #                 edge_type_embed = self.edge_type_embedding_layer(edge_type)
# #     #                 if self.generate_edge_attr:
# #     #                     edge_attr_embed = self.edge_attr_embedding_layer(edge_type)
# #     #                 elif self.edge_attr_embedding_layer:
# #     #                     edge_attr_embed = self.edge_attr_embedding_layer(edge_attr.to(torch.float32))
# #     #                 else:
# #     #                     edge_attr_embed = edge_attr.to(torch.float32)

# #     #             if idx == len(data['edge_index']) - 2:
# #     #                 batch_size = self.eval_batch_size if mode in ('test', 'validate') else self.batch_size
# #     #                 x_target = x_for_time_filter[:batch_size]
# #     #             else:
# #     #                 x_target = x[:edge_index.sparse_sizes()[0]]

# #     #             x = self.conv_list[idx](
# #     #                 (x_for_time_filter, x_target),
# #     #                 edge_index=edge_index,
# #     #                 edge_attr_embed=edge_attr_embed,
# #     #                 edge_time_embed=edge_time_embed,
# #     #                 edge_dist_embed=edge_distance_embed,
# #     #                 edge_type_embed=edge_type_embed
# #     #             )
# #     #             x = self.norms_list[idx](x)
# #     #             x = self.act(x)
# #     #             x = self.dropout_list[idx](x)
# #     #     else:
# #     #         x = x_for_time_filter

# #     #     # === 5. åˆ†ç±»é¢„æµ‹ï¼ˆå°¾äº‹ä»¶ï¼? ===
# #     #     logits = self.linear(x)

# #     #     # === [MODIFIED] åªå–å€™é€‰äº‹ä»¶çš„ logits ===
# #     #     candidates = data.candidates   # [B, K]
# #     #     labels = data.labels

# #     #     B, K = candidates.size()
# #     #     candidate_logits = logits[candidates.view(-1)]  # [B*K, num_event]
# #     #     candidate_logits = candidate_logits.view(B, K, -1)  # [B, K, num_event]

# #     #     if candidate_logits.size(-1) == 1:
# #     #         candidate_logits = candidate_logits.squeeze(-1)  # [B, K]

# #     #     loss = None
# #     #     if labels is not None:
# #     #         loss = self.loss_func(candidate_logits, labels.long())

# #     #     return candidate_logits, loss

# # # import torch
# # # from torch import nn
# # # from layer import (
# # #     CheckinEmbedding,
# # #     EdgeEmbedding,
# # #     HypergraphTransformer,
# # #     TimeEncoder,
# # #     DistanceEncoderHSTLSTM,
# # #     DistanceEncoderSTAN,
# # #     DistanceEncoderSimple
# # # )


# # # class STHGCN(nn.Module):
# # #     def __init__(self, cfg):
# # #         super(STHGCN, self).__init__()
# # #         self.device = cfg.run_args.device
# # #         self.batch_size = cfg.run_args.batch_size
# # #         self.eval_batch_size = cfg.run_args.eval_batch_size
# # #         self.do_traj2traj = cfg.model_args.do_traj2traj
# # #         self.distance_encoder_type = cfg.model_args.distance_encoder_type
# # #         self.dropout_rate = cfg.model_args.dropout_rate
# # #         self.generate_edge_attr = cfg.model_args.generate_edge_attr
# # #         self.num_conv_layers = len(cfg.model_args.sizes)
# # #         self.num_poi = cfg.dataset_args.num_poi
# # #         self.embed_fusion_type = cfg.model_args.embed_fusion_type
# # #         self.fusion_type = getattr(cfg.model_args, "embed_fusion_type",
# # #                     getattr(cfg.model_args, "fusion_type", "concat"))
# # #         # === ä¸‰å±‚è¶…å›¾ Embedding ===
# # #         # self.checkin_embedding_layer = CheckinEmbedding(
# # #         #     embed_size=cfg.model_args.embed_size,
# # #         #     fusion_type=self.embed_fusion_type,
# # #         #     dataset_args=cfg.dataset_args
# # #         # )
# # #         # ---- ä¸‰å±‚è¶…å›¾çš? embedding å±? ----
# # #         # self.embedding_layer = CheckinEmbedding(
# # #         #     embed_size=cfg.model_args.embed_size,
# # #         #     fusion_type=cfg.model_args.fusion_type,
# # #         #     dataset_args=cfg.dataset_args
# # #         # )
# # #         self.checkin_embedding_layer = CheckinEmbedding(
# # #             embed_size=cfg.model_args.embed_size,
# # #             fusion_type=self.fusion_type,
# # #             num_entity=dataset.num_entity,   # â†? æ–°å¢
# # #             num_event=dataset.num_event,     # â†? æ–°å¢
# # #             num_eventchain=dataset.num_eventchain      # â†? æ–°å¢
# # #         )
# # #         self.checkin_embed_size = self.checkin_embedding_layer.output_embed_size  # concat â†? 2*embed_size

# # #         # === è¾¹ç±»å‹åµŒå…? ===
# # #         self.edge_type_embedding_layer = EdgeEmbedding(
# # #             embed_size=self.checkin_embed_size,
# # #             fusion_type=self.embed_fusion_type,
# # #             num_edge_type=cfg.model_args.num_edge_type
# # #         )

# # #         # === æ¿€æ´»å‡½æ•? ===
# # #         if cfg.model_args.activation == 'elu':
# # #             self.act = nn.ELU()
# # #         elif cfg.model_args.activation == 'relu':
# # #             self.act = nn.RReLU()
# # #         elif cfg.model_args.activation == 'leaky_relu':
# # #             self.act = nn.LeakyReLU()
# # #         else:
# # #             self.act = torch.tanh

# # #         # === æ—¶é—´ç¼–ç å™¨ç»´åº? ===
# # #         if cfg.conv_args.time_fusion_mode == 'add':
# # #             continuous_encoder_dim = self.checkin_embed_size
# # #         else:
# # #             continuous_encoder_dim = cfg.model_args.st_embed_size

# # #         # === è¾¹å±æ€§åµŒå…¥å±‚ ===
# # #         if self.generate_edge_attr:
# # #             self.edge_attr_embedding_layer = EdgeEmbedding(
# # #                 embed_size=self.checkin_embed_size,
# # #                 fusion_type=self.embed_fusion_type,
# # #                 num_edge_type=cfg.model_args.num_edge_type
# # #             )
# # #         else:
# # #             if cfg.conv_args.edge_fusion_mode == 'add':
# # #                 self.edge_attr_embedding_layer = nn.Linear(3, self.checkin_embed_size)
# # #             else:
# # #                 self.edge_attr_embedding_layer = None

# # #         # === ç¬¬ä¸€å±? Entityâ†’Event è¶…å›¾å·ç§¯ ===
# # #         self.conv_for_time_filter = HypergraphTransformer(
# # #             in_channels=self.checkin_embed_size,
# # #             out_channels=self.checkin_embed_size,
# # #             attn_heads=cfg.conv_args.num_attention_heads,
# # #             residual_beta=cfg.conv_args.residual_beta,
# # #             learn_beta=cfg.conv_args.learn_beta,
# # #             dropout=cfg.conv_args.conv_dropout_rate,
# # #             trans_method=cfg.conv_args.trans_method,
# # #             edge_fusion_mode=cfg.conv_args.edge_fusion_mode,
# # #             time_fusion_mode=cfg.conv_args.time_fusion_mode,
# # #             head_fusion_mode=cfg.conv_args.head_fusion_mode,
# # #             residual_fusion_mode=None,
# # #             edge_dim=None,
# # #             rel_embed_dim=self.checkin_embed_size,
# # #             time_embed_dim=continuous_encoder_dim,
# # #             dist_embed_dim=continuous_encoder_dim,
# # #             negative_slope=cfg.conv_args.negative_slope,
# # #             have_query_feature=False
# # #         )
# # #         self.norms_for_time_filter = nn.BatchNorm1d(self.checkin_embed_size)
# # #         self.dropout_for_time_filter = nn.Dropout(self.dropout_rate)

# # #         # === Eventâ†’Chain å·ç§¯ï¼ˆå¤šå±‚ï¼‰ ===
# # #         self.conv_list = nn.ModuleList()
# # #         if self.do_traj2traj:
# # #             for i in range(self.num_conv_layers):
# # #                 have_query_feature = (i > 0)
# # #                 residual_fusion_mode = None if i == 0 else cfg.conv_args.residual_fusion_mode
# # #                 edge_size = None if self.edge_attr_embedding_layer is None else self.checkin_embed_size

# # #                 self.conv_list.append(
# # #                     HypergraphTransformer(
# # #                         in_channels=self.checkin_embed_size,
# # #                         out_channels=self.checkin_embed_size,
# # #                         attn_heads=cfg.conv_args.num_attention_heads,
# # #                         residual_beta=cfg.conv_args.residual_beta,
# # #                         learn_beta=cfg.conv_args.learn_beta,
# # #                         dropout=cfg.conv_args.conv_dropout_rate,
# # #                         trans_method=cfg.conv_args.trans_method,
# # #                         edge_fusion_mode=cfg.conv_args.edge_fusion_mode,
# # #                         time_fusion_mode=cfg.conv_args.time_fusion_mode,
# # #                         head_fusion_mode=cfg.conv_args.head_fusion_mode,
# # #                         residual_fusion_mode=residual_fusion_mode,
# # #                         edge_dim=edge_size,
# # #                         rel_embed_dim=self.checkin_embed_size,
# # #                         time_embed_dim=continuous_encoder_dim,
# # #                         dist_embed_dim=continuous_encoder_dim,
# # #                         negative_slope=cfg.conv_args.negative_slope,
# # #                         have_query_feature=have_query_feature
# # #                     )
# # #                 )
# # #             self.norms_list = nn.ModuleList([nn.BatchNorm1d(self.checkin_embed_size) for _ in range(self.num_conv_layers)])
# # #             self.dropout_list = nn.ModuleList([nn.Dropout(self.dropout_rate) for _ in range(self.num_conv_layers)])

# # #         # === æ—¶é—´ + è·ç¦» ç¼–ç å™? ===
# # #         self.continuous_time_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim)
# # #         if self.distance_encoder_type == 'stan':
# # #             self.continuous_distance_encoder = DistanceEncoderSTAN(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
# # #         elif self.distance_encoder_type == 'time':
# # #             self.continuous_distance_encoder = TimeEncoder(cfg.model_args, continuous_encoder_dim)
# # #         elif self.distance_encoder_type == 'hstlstm':
# # #             self.continuous_distance_encoder = DistanceEncoderHSTLSTM(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
# # #         elif self.distance_encoder_type == 'simple':
# # #             self.continuous_distance_encoder = DistanceEncoderSimple(cfg.model_args, continuous_encoder_dim, cfg.dataset_args.spatial_slots)
# # #         else:
# # #             raise ValueError(f"Wrong distance_encoder_type: {self.distance_encoder_type}!")

# # #         # === è¾“å‡ºå±‚ï¼šå°¾äº‹ä»¶åˆ†ç±? ===
# # #         self.linear = nn.Linear(self.checkin_embed_size, cfg.dataset_args.num_event)
# # #         self.loss_func = nn.CrossEntropyLoss()
# # #     def forward(self, data, label=None, mode='train'):
# # #         entity_x, event_x, chain_x = data['x']  # ä¸‰å±‚èŠ‚ç‚¹ç‰¹å¾

# # #         # === 1. èŠ‚ç‚¹åµŒå…¥ ===
# # #         entity_emb = self.checkin_embedding_layer(entity_x)
# # #         event_emb  = self.checkin_embedding_layer(event_x)
# # #         chain_emb  = self.checkin_embedding_layer(chain_x)

# # #         # æ‹¼æ¥æˆç»Ÿä¸€è¡¨ç¤º
# # #         x = torch.cat([entity_emb, event_emb, chain_emb], dim=0)

# # #         # === 2. è¾¹çš„æ—¶é—´/ç©ºé—´ç‰¹å¾ï¼ˆEntityâ†’Eventï¼? ===
# # #         edge_time_embed = self.continuous_time_encoder(data['delta_ts'][0] / (60 * 60))
# # #         if self.distance_encoder_type == 'stan':
# # #             edge_distance_embed = self.continuous_distance_encoder(data['delta_ss'][0], dist_type='entity2event')
# # #         else:
# # #             edge_distance_embed = self.continuous_distance_encoder(data['delta_ss'][0])

# # #         # === 3. Entityâ†’Event å·ç§¯ ===
# # #         edge_attr_embed, edge_type_embed = None, None
# # #         if data['edge_type'][0] is not None:
# # #             if self.generate_edge_attr:
# # #                 edge_attr_embed = self.edge_attr_embedding_layer(data['edge_type'][0])
# # #             edge_type_embed = self.edge_type_embedding_layer(data['edge_type'][0])

# # #         entity_event_out = self.conv_for_time_filter(
# # #             x,
# # #             edge_index=data['edge_index'][0],
# # #             edge_attr_embed=edge_attr_embed,
# # #             edge_time_embed=edge_time_embed,
# # #             edge_dist_embed=edge_distance_embed,
# # #             edge_type_embed=edge_type_embed
# # #         )
# # #         entity_event_out = self.norms_for_time_filter(entity_event_out)
# # #         entity_event_out = self.act(entity_event_out)
# # #         entity_event_out = self.dropout_for_time_filter(entity_event_out)

# # #         # === 4. Eventâ†’Chain å·ç§¯ ===
# # #         if data['edge_index'][-1] is not None and self.do_traj2traj:
# # #             for idx, (edge_index, edge_attr, delta_ts, delta_dis, edge_type) in enumerate(
# # #                     zip(data["edge_index"][1:], data["edge_attr"][1:], data["delta_ts"][1:], data["delta_ss"][1:], data["edge_type"][1:])
# # #             ):
# # #                 edge_time_embed = self.continuous_time_encoder(delta_ts / (60 * 60))
# # #                 if self.distance_encoder_type == 'stan':
# # #                     edge_distance_embed = self.continuous_distance_encoder(delta_dis, dist_type='event2chain')
# # #                 else:
# # #                     edge_distance_embed = self.continuous_distance_encoder(delta_dis)

# # #                 edge_attr_embed, edge_type_embed = None, None
# # #                 if edge_type is not None:
# # #                     edge_type_embed = self.edge_type_embedding_layer(edge_type)
# # #                     if self.generate_edge_attr:
# # #                         edge_attr_embed = self.edge_attr_embedding_layer(edge_type)
# # #                     elif self.edge_attr_embedding_layer:
# # #                         edge_attr_embed = self.edge_attr_embedding_layer(edge_attr.to(torch.float32))
# # #                     else:
# # #                         edge_attr_embed = edge_attr.to(torch.float32)

# # #                 if idx == len(data['edge_index']) - 2:
# # #                     batch_size = self.eval_batch_size if mode in ('test', 'validate') else self.batch_size
# # #                     x_target = entity_event_out[:batch_size]
# # #                 else:
# # #                     x_target = x[:edge_index.sparse_sizes()[0]]

# # #                 x = self.conv_list[idx](
# # #                     (entity_event_out, x_target),
# # #                     edge_index=edge_index,
# # #                     edge_attr_embed=edge_attr_embed,
# # #                     edge_time_embed=edge_time_embed,
# # #                     edge_dist_embed=edge_distance_embed,
# # #                     edge_type_embed=edge_type_embed
# # #                 )
# # #                 x = self.norms_list[idx](x)
# # #                 x = self.act(x)
# # #                 x = self.dropout_list[idx](x)
# # #         else:
# # #             x = entity_event_out

# # #         # === 5. åˆ†ç±»é¢„æµ‹ï¼ˆå°¾äº‹ä»¶ï¼? ===
# # #         logits = self.linear(x)

# # #         # === [MODIFIED] åªå–å€™é€‰äº‹ä»¶çš„ logits ===
# # #         candidates = data.candidates
# # #         label = data.labels

# # #         #candidates = data['candidates']   # [B, K]
# # #         B, K = candidates.size()
# # #         # logits åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„åˆ†æ•°ï¼Œè¿™é‡Œåªå–å‡ºå€™é€‰äº‹ä»¶çš„
# # #         candidate_logits = logits[candidates.view(-1)]  # [B*K, num_classes]
# # #         candidate_logits = candidate_logits.view(B, K, -1)  # [B, K, num_classes]

# # #         # å¦‚æœæ˜¯äºŒåˆ†ç±»ï¼Œå¯ä»¥ç›´æ? squeeze
# # #         if candidate_logits.size(-1) == 1:
# # #             candidate_logits = candidate_logits.squeeze(-1)  # [B, K]

# # #         loss = None
# # #         if label is not None:
# # #             # label: [B], æ¯ä¸ªæ ·æœ¬åœ? [0, K-1] å†?
# # #             loss = self.loss_func(candidate_logits, label.long())

# # #         return candidate_logits, loss

# #     # def forward(self, data, label=None, mode='train'):
# #     #     # === [MODIFIED] è§£åŒ…ä¸‰å±‚èŠ‚ç‚¹ç‰¹å¾ ===
# #     #     entity_x, event_x, chain_x = data['x']  # (entity_x, event_x, chain_x)

# #     #     # === [MODIFIED] ä¸‰å±‚åˆ†åˆ«å? embedding ===
# #     #     entity_emb = self.checkin_embedding_layer(entity_x)
# #     #     event_emb  = self.checkin_embedding_layer(event_x)
# #     #     chain_emb  = self.checkin_embedding_layer(chain_x)

# #     #     # === [MODIFIED] æ‹¼æ¥æˆç»Ÿä¸€ç©ºé—´è¡¨ç¤ºï¼ˆå¯é€‰ï¼Œå…¼å®¹æ—§é€»è¾‘ï¼? ===
# #     #     x = torch.cat([entity_emb, event_emb, chain_emb], dim=0)

# #     #     # === 2. è¾¹çš„æ—¶é—´/ç©ºé—´ç‰¹å¾ï¼ˆEntityâ†’Eventï¼? ===
# #     #     edge_time_embed = self.continuous_time_encoder(data['delta_ts'][0] / (60 * 60))
# #     #     if self.distance_encoder_type == 'stan':
# #     #         edge_distance_embed = self.continuous_distance_encoder(data['delta_ss'][0], dist_type='entity2event')
# #     #     else:
# #     #         edge_distance_embed = self.continuous_distance_encoder(data['delta_ss'][0])

# #     #     # === 3. Entityâ†’Event å·ç§¯ ===
# #     #     edge_attr_embed, edge_type_embed = None, None
# #     #     if data['edge_type'][0] is not None:
# #     #         if self.generate_edge_attr:
# #     #             edge_attr_embed = self.edge_attr_embedding_layer(data['edge_type'][0])
# #     #         edge_type_embed = self.edge_type_embedding_layer(data['edge_type'][0])

# #     #     entity_event_out = self.conv_for_time_filter(
# #     #         x,
# #     #         edge_index=data['edge_index'][0],
# #     #         edge_attr_embed=edge_attr_embed,
# #     #         edge_time_embed=edge_time_embed,
# #     #         edge_dist_embed=edge_distance_embed,
# #     #         edge_type_embed=edge_type_embed
# #     #     )
# #     #     entity_event_out = self.norms_for_time_filter(entity_event_out)
# #     #     entity_event_out = self.act(entity_event_out)
# #     #     entity_event_out = self.dropout_for_time_filter(entity_event_out)

# #     #     # === 4. Eventâ†’Chain å·ç§¯ ===
# #     #     if data['edge_index'][-1] is not None and self.do_traj2traj:
# #     #         for idx, (edge_index, edge_attr, delta_ts, delta_dis, edge_type) in enumerate(
# #     #                 zip(data["edge_index"][1:], data["edge_attr"][1:], data["delta_ts"][1:], data["delta_ss"][1:], data["edge_type"][1:])
# #     #         ):
# #     #             edge_time_embed = self.continuous_time_encoder(delta_ts / (60 * 60))
# #     #             if self.distance_encoder_type == 'stan':
# #     #                 edge_distance_embed = self.continuous_distance_encoder(delta_dis, dist_type='event2chain')
# #     #             else:
# #     #                 edge_distance_embed = self.continuous_distance_encoder(delta_dis)

# #     #             edge_attr_embed, edge_type_embed = None, None
# #     #             if edge_type is not None:
# #     #                 edge_type_embed = self.edge_type_embedding_layer(edge_type)
# #     #                 if self.generate_edge_attr:
# #     #                     edge_attr_embed = self.edge_attr_embedding_layer(edge_type)
# #     #                 elif self.edge_attr_embedding_layer:
# #     #                     edge_attr_embed = self.edge_attr_embedding_layer(edge_attr.to(torch.float32))
# #     #                 else:
# #     #                     edge_attr_embed = edge_attr.to(torch.float32)

# #     #             if idx == len(data['edge_index']) - 2:
# #     #                 batch_size = self.eval_batch_size if mode in ('test', 'validate') else self.batch_size
# #     #                 x_target = entity_event_out[:batch_size]
# #     #             else:
# #     #                 x_target = x[:edge_index.sparse_sizes()[0]]

# #     #             x = self.conv_list[idx](
# #     #                 (entity_event_out, x_target),   # [MODIFIED] è¾“å…¥æ¢æˆ entity_event_out
# #     #                 edge_index=edge_index,
# #     #                 edge_attr_embed=edge_attr_embed,
# #     #                 edge_time_embed=edge_time_embed,
# #     #                 edge_dist_embed=edge_distance_embed,
# #     #                 edge_type_embed=edge_type_embed
# #     #             )
# #     #             x = self.norms_list[idx](x)
# #     #             x = self.act(x)
# #     #             x = self.dropout_list[idx](x)
# #     #     else:
# #     #         x = entity_event_out

# #     #     # === 5. åˆ†ç±»é¢„æµ‹ï¼ˆå°¾äº‹ä»¶ï¼? ===
# #     #     logits = self.linear(x)
# #     #     loss = None
# #     #     if label is not None:
# #     #         loss = self.loss_func(logits, label.long())
# #     #     return logits, loss

# #     # # def forward(self, data, label=None, mode='train'):
# #     # #     entity_x, event_x, chain_x = data['x']  # ä¸‰å±‚èŠ‚ç‚¹ç‰¹å¾

# #     # #     # === 1. èŠ‚ç‚¹åµŒå…¥ ===
# #     # #     x = self.checkin_embedding_layer(entity_x, event_x, chain_x)

# #     # #     # === 2. è¾¹çš„æ—¶é—´/ç©ºé—´ç‰¹å¾ ===
# #     # #     edge_time_embed = self.continuous_time_encoder(data['delta_ts'][0] / (60 * 60))
# #     # #     if self.distance_encoder_type == 'stan':
# #     # #         edge_distance_embed = self.continuous_distance_encoder(data['delta_ss'][0], dist_type='entity2event')
# #     # #     else:
# #     # #         edge_distance_embed = self.continuous_distance_encoder(data['delta_ss'][0])

# #     # #     # === 3. Entityâ†’Event å·ç§¯ ===
# #     # #     edge_attr_embed, edge_type_embed = None, None
# #     # #     if data['edge_type'][0] is not None:
# #     # #         if self.generate_edge_attr:
# #     # #             edge_attr_embed = self.edge_attr_embedding_layer(data['edge_type'][0])
# #     # #         edge_type_embed = self.edge_type_embedding_layer(data['edge_type'][0])

# #     # #     x_for_time_filter = self.conv_for_time_filter(
# #     # #         x,
# #     # #         edge_index=data['edge_index'][0],
# #     # #         edge_attr_embed=edge_attr_embed,
# #     # #         edge_time_embed=edge_time_embed,
# #     # #         edge_dist_embed=edge_distance_embed,
# #     # #         edge_type_embed=edge_type_embed
# #     # #     )
# #     # #     x_for_time_filter = self.norms_for_time_filter(x_for_time_filter)
# #     # #     x_for_time_filter = self.act(x_for_time_filter)
# #     # #     x_for_time_filter = self.dropout_for_time_filter(x_for_time_filter)

# #     # #     # === 4. Eventâ†’Chain å·ç§¯ ===
# #     # #     if data['edge_index'][-1] is not None and self.do_traj2traj:
# #     # #         for idx, (edge_index, edge_attr, delta_ts, delta_dis, edge_type) in enumerate(
# #     # #                 zip(data["edge_index"][1:], data["edge_attr"][1:], data["delta_ts"][1:], data["delta_ss"][1:], data["edge_type"][1:])
# #     # #         ):
# #     # #             edge_time_embed = self.continuous_time_encoder(delta_ts / (60 * 60))
# #     # #             if self.distance_encoder_type == 'stan':
# #     # #                 edge_distance_embed = self.continuous_distance_encoder(delta_dis, dist_type='event2chain')
# #     # #             else:
# #     # #                 edge_distance_embed = self.continuous_distance_encoder(delta_dis)

# #     # #             edge_attr_embed, edge_type_embed = None, None
# #     # #             if edge_type is not None:
# #     # #                 edge_type_embed = self.edge_type_embedding_layer(edge_type)
# #     # #                 if self.generate_edge_attr:
# #     # #                     edge_attr_embed = self.edge_attr_embedding_layer(edge_type)
# #     # #                 elif self.edge_attr_embedding_layer:
# #     # #                     edge_attr_embed = self.edge_attr_embedding_layer(edge_attr.to(torch.float32))
# #     # #                 else:
# #     # #                     edge_attr_embed = edge_attr.to(torch.float32)

# #     # #             if idx == len(data['edge_index']) - 2:
# #     # #                 batch_size = self.eval_batch_size if mode in ('test', 'validate') else self.batch_size
# #     # #                 x_target = x_for_time_filter[:batch_size]
# #     # #             else:
# #     # #                 x_target = x[:edge_index.sparse_sizes()[0]]

# #     # #             x = self.conv_list[idx](
# #     # #                 (x, x_target),
# #     # #                 edge_index=edge_index,
# #     # #                 edge_attr_embed=edge_attr_embed,
# #     # #                 edge_time_embed=edge_time_embed,
# #     # #                 edge_dist_embed=edge_distance_embed,
# #     # #                 edge_type_embed=edge_type_embed
# #     # #             )
# #     # #             x = self.norms_list[idx](x)
# #     # #             x = self.act(x)
# #     # #             x = self.dropout_list[idx](x)
# #     # #     else:
# #     # #         x = x_for_time_filter

# #     # #     # === 5. åˆ†ç±»é¢„æµ‹ï¼ˆå°¾äº‹ä»¶ï¼? ===
# #     # #     logits = self.linear(x)
# #     # #     loss = None
# #     # #     if label is not None:
# #     # #         loss = self.loss_func(logits, label.long())
# #     # #     return logits, loss

